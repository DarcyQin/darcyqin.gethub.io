---
layout: post
title:  "隐马尔可夫链"
date:   2019-06-22 00:30
categories: algorithm
tags: algorithm, ML
excerpt: 
mathjax: true
---

* content
{:toc}

### 前言
隐马尔可夫模型（Hidden Markov Model，简称HMM），是可以用来标注问题的统计学习模型，描述由马尔可夫链随机生成观测序列的过程，属于生成式模型。
在正常的马尔可夫模型中，状态对于观测者来说是直接可见的。这样状态的转换概率便是全部的参数。而在隐马尔可夫模型中，状态并不是直接可见的，但是受状态影响的某些变量是可见的。每一个状态在可能输出的符号上都有一个概率分布，因此输出序列能否透露出状态序列的一些信息。

### HMM模型的定义
隐马尔可夫模型由初始概率分布，状态转移概率分布以及观测概率分布确定。
我们假设Q是所有可能的隐藏状态的集合，V是所有可能的观测状态的集合，即：

$$Q={q_1,q_2,...,q_N},V={v_1,v_2,...,v_M}$$

其中，N是可能的状态数，M是可能的观测数。
I是长度为T的状态序列，O是对应的观测序列。

$$I=(i_1,i_2,...,i_T), O=(o_1,o_2,...,o_T)$$

A是状态转移概率矩阵：

$$A=[a_{ij}]_{N*N}$$

其中，

$$a_{ij}=P(i_{t+1}|i_t=q_i),  i=1,2,...,N; j=1,2,...,N$$

表示在时刻t处于状态$q_i$的条件下在时刻t+1转移到状态$q_j$的概率。

B是观测概率矩阵：

$$B=[b_j(k)]_{N*M}$$

其中，

$$b_j(k)=P(o_t=v_k|i_t=q_j), k=1,2,...,M;j=1,2,...,N$$

表示在时刻t处于状态$q_j$的条件下生成观测$v_k$的概率。

$\pi$是初始状态概率向量：

$$\pi=(\pi_i)$$

其中：

$$\pi_i=P(i_1=q_i),i=1,2,...,N$$

表示时刻t=1处于状态$q_i$的概率。

一个马尔可夫模型，可以有隐藏状态的初始概率分布$\pi$，状态转移矩阵A和观测状态转移矩阵B决定，$\pi$，A决定状态序列，B决定观测序列。因此，隐马尔可夫模型$\lambda$可以用三员符号表示，即：

$$\lambda=(A,B,\pi)$$


$\pi$,A,B称为隐马尔可夫模型的三要素。

隐马尔可夫做了两个很重要的基本能假设：

1、齐次马尔可夫假设，即假设隐藏的马尔可夫链在任意时刻t的状态只依赖于前一时刻的状态，于其他时刻的状态及观察无关，也与时刻t无关，即：

$$P(i_t|i_{t-1},o_{t-1},...,i_1,o_1)=P(i_t|i_{t-1})$$

2、观察独立性假设，即假设任意时刻的观测值依赖于该时刻的马尔可夫链的状态，与其他观测及状态无关，即：

$$P(o_t|i_T,o_T,...,i_{t+1},o_{t+1},...,i_1,o_1)=P(o_t|i_t)$$





